{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christiangalleisky/Basic_File_IO_with_Unit_Tests/blob/master/Copy_of_Joseph_Lopez_And_Christian_Homework_2_USETHISONE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriptions of the dataset\n",
        "#The datset is split into ten seperate labels 0-9 with descriptions\n",
        "#0 - airplane\n",
        "#1 - automobile\n",
        "#2 - bird\n",
        "#3 - cat\n",
        "#4 - deer\n",
        "#5 - dog\n",
        "#6 - frog\n",
        "#7 - horse\n",
        "#8 - ship\n",
        "#9 - truck\n",
        "\n",
        "#dataset consists of 50,000 32x32 color images for training, and 10,000 for testing "
      ],
      "metadata": {
        "id": "WHN8whiTJEXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import model_to_dot\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import activations\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "assert x_train.shape == (50000, 32, 32, 3)\n",
        "assert x_test.shape == (10000, 32, 32, 3)\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)\n",
        "\n",
        "\n",
        "#2-SPLIT AND SHAPE\n",
        "x_train = x_train.reshape(50000, 3072).astype('float32') / 255\n",
        "x_test = x_test.reshape(10000, 3072).astype('float32') / 255\n",
        "\n",
        "n_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, n_classes)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "I chose the sigmoid function becuase it was in the tutorial\n",
        "thus helping me to get to operation faster\n",
        "'''\n",
        "#4/3-FIRST NEURAL NET\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation = 'sigmoid', input_shape = (3072,)))\n",
        "model.add(Dense(10, activation = 'softmax'))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs = 20, verbose = 1,\n",
        "          validation_data = (x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"SIGMOID FUNCTION\")\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "\n",
        "'''\n",
        "I chose the reLU function because it is supposed\n",
        "to be versatile\n",
        "'''\n",
        "#4/3-SECOND NEURAL NET\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(64, activation = 'relu', input_shape = (3072,)))\n",
        "model1.add(Dense(10, activation = 'softmax'))\n",
        "model1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model1.fit(x_train, y_train, epochs = 20, verbose = 1,\n",
        "          validation_data = (x_test, y_test))\n",
        "score = model1.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"ReLU FUNCTION\")\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "\n",
        "'''\n",
        "I chose the tanh function becuase I like how it is\n",
        "centered around 0.\n",
        "'''\n",
        "#4/3-THIRD NEURAL NET\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(64, activation = 'tanh', input_shape = (3072,)))\n",
        "model2.add(Dense(10, activation = 'softmax'))\n",
        "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model2.fit(x_train, y_train, epochs = 20, verbose = 1,\n",
        "          validation_data = (x_test, y_test))\n",
        "score = model2.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"HYPERBOLIC TANGENT FUNCTION\")\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "\n",
        "#5#TESTED AND TUNED N.N.\n",
        "\n",
        "#Three diff layer depths\n",
        "\n",
        "#128 NEURAL NET\n",
        "\n",
        "model128 = Sequential()\n",
        "model128.add(Dense(128, activation = 'sigmoid', input_shape = (3072,)))\n",
        "model128.add(Dense(10, activation = 'softmax'))\n",
        "model128.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model128.fit(x_train, y_train, epochs = 20, verbose = 1,\n",
        "          validation_data = (x_test, y_test))\n",
        "score = model128.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"128 NEURONS\")\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "\n",
        "#256 NEURAL NET\n",
        "\n",
        "model256 = Sequential()\n",
        "model256.add(Dense(256, activation = 'sigmoid', input_shape = (3072,)))\n",
        "model256.add(Dense(10, activation = 'softmax'))\n",
        "model256.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model256.fit(x_train, y_train, epochs = 20, verbose = 1,\n",
        "          validation_data = (x_test, y_test))\n",
        "score = model256.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"256 NEURONS\")\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "\n",
        "#512 NEURAL NET\n",
        "\n",
        "model512 = Sequential()\n",
        "model512.add(Dense(512, activation = 'sigmoid', input_shape = (3072,)))\n",
        "model512.add(Dense(10, activation = 'softmax'))\n",
        "model512.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model512.fit(x_train, y_train, epochs = 20, verbose = 1,\n",
        "          validation_data = (x_test, y_test))\n",
        "score = model512.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"512 NEURONS\")\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "\n",
        "#5\n",
        "#Two layer NEURAL NET\n",
        "\n",
        "model2Nets = Sequential()\n",
        "model2Nets.add(Dense(32, activation = 'relu', input_shape = (3072,)))\n",
        "model2Nets.add(Dense(64, activation = 'sigmoid', input_shape = (3072,)))\n",
        "model2Nets.add(Dense(10, activation = 'softmax'))\n",
        "model2Nets.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model2Nets.fit(x_train, y_train, epochs = 20, verbose = 1,\n",
        "          validation_data = (x_test, y_test))\n",
        "score = model2Nets.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"2 HIDDEN LAYERS\")\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "#5\n",
        "#Diff op and diff loss function\n",
        "modelo = Sequential()\n",
        "modelo.add(Dense(64, activation = 'sigmoid', input_shape = (3072,)))\n",
        "modelo.add(Dense(10, activation = 'softmax'))\n",
        "modelo.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
        "modelo.fit(x_train, y_train, epochs = 20, verbose = 1,\n",
        "          validation_data = (x_test, y_test))\n",
        "score = modelo.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"DIFFERENT OPTIMIZER\")\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "modelL = Sequential()\n",
        "modelL.add(Dense(64, activation = 'sigmoid', input_shape = (3072,)))\n",
        "modelL.add(Dense(10, activation = 'softmax'))\n",
        "modelL.compile(loss=\"poisson\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "modelL.fit(x_train, y_train, epochs = 20, verbose = 1,\n",
        "          validation_data = (x_test, y_test))\n",
        "score = modelL.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"DIFFERENT LOSS FUNC\")\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ThnaVsclyZ6w",
        "outputId": "c6866dcd-0f9e-410b-b666-12ba13894dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.8964 - accuracy: 0.3265 - val_loss: 1.7796 - val_accuracy: 0.3782\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7553 - accuracy: 0.3785 - val_loss: 1.7655 - val_accuracy: 0.3771\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6984 - accuracy: 0.3971 - val_loss: 1.6887 - val_accuracy: 0.4025\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6671 - accuracy: 0.4082 - val_loss: 1.6877 - val_accuracy: 0.3954\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6382 - accuracy: 0.4178 - val_loss: 1.6222 - val_accuracy: 0.4132\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6172 - accuracy: 0.4258 - val_loss: 1.6317 - val_accuracy: 0.4150\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6023 - accuracy: 0.4307 - val_loss: 1.6074 - val_accuracy: 0.4258\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5808 - accuracy: 0.4374 - val_loss: 1.6059 - val_accuracy: 0.4261\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5647 - accuracy: 0.4454 - val_loss: 1.5756 - val_accuracy: 0.4404\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5491 - accuracy: 0.4501 - val_loss: 1.5772 - val_accuracy: 0.4419\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5415 - accuracy: 0.4525 - val_loss: 1.5826 - val_accuracy: 0.4328\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5334 - accuracy: 0.4554 - val_loss: 1.5858 - val_accuracy: 0.4362\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5186 - accuracy: 0.4611 - val_loss: 1.5947 - val_accuracy: 0.4331\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5153 - accuracy: 0.4611 - val_loss: 1.5657 - val_accuracy: 0.4446\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5145 - accuracy: 0.4621 - val_loss: 1.5541 - val_accuracy: 0.4443\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5058 - accuracy: 0.4641 - val_loss: 1.5668 - val_accuracy: 0.4472\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4982 - accuracy: 0.4659 - val_loss: 1.5592 - val_accuracy: 0.4378\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4871 - accuracy: 0.4718 - val_loss: 1.5788 - val_accuracy: 0.4292\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.4839 - accuracy: 0.4725 - val_loss: 1.5580 - val_accuracy: 0.4432\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4791 - accuracy: 0.4762 - val_loss: 1.5523 - val_accuracy: 0.4500\n",
            "Test loss: 1.5522812604904175\n",
            "Test accuracy: 0.44999998807907104\n",
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.9189 - accuracy: 0.3071 - val_loss: 1.7955 - val_accuracy: 0.3531\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7881 - accuracy: 0.3542 - val_loss: 1.8180 - val_accuracy: 0.3443\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7333 - accuracy: 0.3745 - val_loss: 1.8042 - val_accuracy: 0.3385\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7057 - accuracy: 0.3842 - val_loss: 1.6942 - val_accuracy: 0.3881\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6949 - accuracy: 0.3894 - val_loss: 1.6786 - val_accuracy: 0.3883\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6801 - accuracy: 0.3957 - val_loss: 1.6588 - val_accuracy: 0.3960\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6725 - accuracy: 0.3983 - val_loss: 1.6803 - val_accuracy: 0.3917\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6627 - accuracy: 0.4024 - val_loss: 1.6567 - val_accuracy: 0.4044\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6574 - accuracy: 0.4039 - val_loss: 1.6793 - val_accuracy: 0.3903\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6455 - accuracy: 0.4092 - val_loss: 1.6813 - val_accuracy: 0.3895\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6408 - accuracy: 0.4120 - val_loss: 1.6433 - val_accuracy: 0.4048\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6337 - accuracy: 0.4142 - val_loss: 1.6358 - val_accuracy: 0.4085\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6261 - accuracy: 0.4155 - val_loss: 1.6590 - val_accuracy: 0.3983\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6251 - accuracy: 0.4159 - val_loss: 1.6214 - val_accuracy: 0.4179\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6180 - accuracy: 0.4171 - val_loss: 1.6740 - val_accuracy: 0.3985\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6161 - accuracy: 0.4194 - val_loss: 1.6627 - val_accuracy: 0.4000\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6110 - accuracy: 0.4187 - val_loss: 1.6346 - val_accuracy: 0.4109\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6081 - accuracy: 0.4206 - val_loss: 1.6377 - val_accuracy: 0.4062\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6026 - accuracy: 0.4217 - val_loss: 1.6401 - val_accuracy: 0.4004\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6003 - accuracy: 0.4251 - val_loss: 1.6428 - val_accuracy: 0.4041\n",
            "Test loss: 1.6427767276763916\n",
            "Test accuracy: 0.4041000008583069\n",
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.9733 - accuracy: 0.2866 - val_loss: 1.8731 - val_accuracy: 0.3342\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8663 - accuracy: 0.3281 - val_loss: 1.8381 - val_accuracy: 0.3455\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8278 - accuracy: 0.3457 - val_loss: 1.8325 - val_accuracy: 0.3476\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8163 - accuracy: 0.3492 - val_loss: 1.8128 - val_accuracy: 0.3577\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7911 - accuracy: 0.3583 - val_loss: 1.7903 - val_accuracy: 0.3668\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7790 - accuracy: 0.3648 - val_loss: 1.7698 - val_accuracy: 0.3685\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7650 - accuracy: 0.3687 - val_loss: 1.8035 - val_accuracy: 0.3582\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7564 - accuracy: 0.3741 - val_loss: 1.7841 - val_accuracy: 0.3643\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7459 - accuracy: 0.3750 - val_loss: 1.7828 - val_accuracy: 0.3535\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7403 - accuracy: 0.3781 - val_loss: 1.7652 - val_accuracy: 0.3667\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7300 - accuracy: 0.3834 - val_loss: 1.7263 - val_accuracy: 0.3801\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7258 - accuracy: 0.3843 - val_loss: 1.7200 - val_accuracy: 0.3855\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7202 - accuracy: 0.3838 - val_loss: 1.7338 - val_accuracy: 0.3865\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7183 - accuracy: 0.3856 - val_loss: 1.7413 - val_accuracy: 0.3747\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7064 - accuracy: 0.3895 - val_loss: 1.7441 - val_accuracy: 0.3773\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7107 - accuracy: 0.3901 - val_loss: 1.7340 - val_accuracy: 0.3840\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6941 - accuracy: 0.3953 - val_loss: 1.6970 - val_accuracy: 0.3987\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6932 - accuracy: 0.3932 - val_loss: 1.7307 - val_accuracy: 0.3931\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6852 - accuracy: 0.3982 - val_loss: 1.6844 - val_accuracy: 0.4031\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6809 - accuracy: 0.3990 - val_loss: 1.7190 - val_accuracy: 0.3936\n",
            "Test loss: 1.7189922332763672\n",
            "Test accuracy: 0.3935999870300293\n",
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.8881 - accuracy: 0.3270 - val_loss: 1.7720 - val_accuracy: 0.3654\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7506 - accuracy: 0.3790 - val_loss: 1.7198 - val_accuracy: 0.3879\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6957 - accuracy: 0.3952 - val_loss: 1.6681 - val_accuracy: 0.4058\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6579 - accuracy: 0.4106 - val_loss: 1.6719 - val_accuracy: 0.4060\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6315 - accuracy: 0.4198 - val_loss: 1.6353 - val_accuracy: 0.4231\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6049 - accuracy: 0.4290 - val_loss: 1.5989 - val_accuracy: 0.4294\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5893 - accuracy: 0.4332 - val_loss: 1.6095 - val_accuracy: 0.4256\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5749 - accuracy: 0.4403 - val_loss: 1.6006 - val_accuracy: 0.4282\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5622 - accuracy: 0.4448 - val_loss: 1.5772 - val_accuracy: 0.4359\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5539 - accuracy: 0.4472 - val_loss: 1.6064 - val_accuracy: 0.4249\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5424 - accuracy: 0.4512 - val_loss: 1.6128 - val_accuracy: 0.4205\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5301 - accuracy: 0.4543 - val_loss: 1.5726 - val_accuracy: 0.4400\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5223 - accuracy: 0.4579 - val_loss: 1.6178 - val_accuracy: 0.4314\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5185 - accuracy: 0.4588 - val_loss: 1.5580 - val_accuracy: 0.4516\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5095 - accuracy: 0.4617 - val_loss: 1.6130 - val_accuracy: 0.4283\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5030 - accuracy: 0.4641 - val_loss: 1.5872 - val_accuracy: 0.4400\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5040 - accuracy: 0.4639 - val_loss: 1.5732 - val_accuracy: 0.4423\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4935 - accuracy: 0.4668 - val_loss: 1.5514 - val_accuracy: 0.4501\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4782 - accuracy: 0.4729 - val_loss: 1.5564 - val_accuracy: 0.4473\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4733 - accuracy: 0.4747 - val_loss: 1.5491 - val_accuracy: 0.4505\n",
            "Test loss: 1.5490790605545044\n",
            "Test accuracy: 0.4505000114440918\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-dbecdbe1d849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mmodel256\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mmode256\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3072\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0mmodel256\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mmodel256\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mode256' is not defined"
          ]
        }
      ]
    }
  ]
}